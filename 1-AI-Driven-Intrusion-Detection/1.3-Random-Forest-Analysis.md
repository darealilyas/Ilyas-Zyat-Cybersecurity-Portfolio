## Overview

After generating adversarial traffic and analysing signature-based detection with Snort, the next step was to evaluate how a machine-learning intrusion detection model performs against realistic attack behaviour. A Random Forest classifier trained on CIC-IDS2017 was used to analyse traffic patterns and determine whether behavioural detection can complement traditional IDS monitoring.

The objective here was not to develop a new AI model, but to assess how well an existing machine-learning approach identifies penetration testing activity compared to signature-based detection.

---

## Random Forest Model

A Random Forest classifier was used due to its reliability in classification tasks involving structured network traffic features. The model was trained beforehand using CIC-IDS2017 traffic data and then applied to traffic generated during the adversarial testing phase.

Below is the core prediction workflow used to classify network flows:

<p align="center">
  <img src="https://raw.githubusercontent.com/darealilyas/Ilyas-Zyat-Cybersecurity-Portfolio/main/1-AI-Driven-Intrusion-Detection/assets/rf.png" width="750">
</p>
<p align="center">
  <em>Random Forest model loading and prediction workflow.</em>
</p>

This allowed classification of network behaviour rather than reliance on predefined attack signatures.

---

## Detection Results

The evaluation shows strong detection performance for common attack categories that are well represented in the training dataset. Weighted performance metrics remain high, indicating effective detection for dominant traffic classes.

<p align="center">
  <img src="https://raw.githubusercontent.com/darealilyas/Ilyas-Zyat-Cybersecurity-Portfolio/main/1-AI-Driven-Intrusion-Detection/assets/overall-perf.png" width="750">
</p>
<p align="center">
  <em>Overall model performance metrics.</em>
</p>

However, macro-average results highlight reduced performance on rare attack classes, reflecting dataset imbalance and limited representation of certain attack types.

---

## Traffic Classification Insights

Analysis of class-level performance shows a clear difference between frequently occurring attacks and less represented ones.

<p align="center">
  <img src="https://raw.githubusercontent.com/darealilyas/Ilyas-Zyat-Cybersecurity-Portfolio/main/1-AI-Driven-Intrusion-Detection/assets/high-score.png" width="750">
</p>
<p align="center">
  <em>High-scoring attack classes.</em>
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/darealilyas/Ilyas-Zyat-Cybersecurity-Portfolio/main/1-AI-Driven-Intrusion-Detection/assets/low-score.png" width="750">
</p>
<p align="center">
  <em>Lower-performing attack classes.</em>
</p>

This confirms a known limitation of machine-learning intrusion detection systems: performance strongly depends on training data distribution.

---

## Limitations Observed

Several important observations emerged from this analysis:

- Dataset imbalance significantly affects classification reliability
- Rare or complex attacks are harder for the model to detect
- Signature-based IDS remains effective for known attacks
- Machine learning provides behavioural detection but requires diverse training data

This reinforces the value of hybrid intrusion detection approaches combining traditional IDS with AI-based analysis.

---

## Recommendations and Future Work

Future improvements should focus on:

- Expanding adversarial traffic diversity for better model evaluation
- Addressing dataset imbalance through improved training data
- Testing real-time integration of AI-assisted IDS monitoring
- Further exploration of hybrid detection architectures combining signatures and behavioural models
